---
layout: default
---
<body>
<div id="content">
<h1 class="title">README</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Re-imaging the empirical: statistical visualisation in art and science</a>
<ul>
<li><a href="#sec-1-1">1.1. Project Description</a></li>
<li><a href="#sec-1-2">1.2. Project Outline</a></li>
<li><a href="#sec-1-3">1.3. Code</a></li>
<li><a href="#sec-1-4">1.4. Project Methodology</a></li>
<li><a href="#sec-1-5">1.5. People</a></li>
<li><a href="#sec-1-6">1.6. Licence</a></li>
<li><a href="#sec-1-7">1.7. Credits</a></li>
<li><a href="#sec-1-8">1.8. Acknowledgements</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Re-imaging the empirical: statistical visualisation in art and science</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Project Description</h3>
<div class="outline-text-3" id="text-1-1">
<p>
The increasing overlap of popular, scientific and aesthetic dimensions of visual culture with data analytical techniques is leading to a new kind of statistical visual culture. Yet there is scant literacy or understanding of statistical visualisation's role in empirical domains today. This research project aims to investigate how statistical images re-shape diverse knowledge domains and practices from facial recognition to medical diagnosis to video-tagging. Equally it will discern how arts-led visualisation transforms statistical image conventions and techniques. It aims to improve visual literacies and dialogue across communities of practice in art and science, and has the
potential to communicate the value and role of statistics today.
</p>
</div>
</div>
<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Project Outline</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>Downloading and extracting the arXiv source dataset - see <i>arxiv<sub>extract</sub>.sh</i>
</li>
<li>Creating an SQLite database to index each image and link to metadata - <i>sqlite-scripts</i>
</li>
<li>Querying dataset for various statistics regarding image formats, dimensions, category distributions etc. - see <i>statistics</i>, e.g. <i>general data statistics</i>
</li>
<li>Running machine learning techniques such as image classification and dimensionality reduction across data
</li>
<li>Producing t-SNE maps of the distribution of different image features within subsets of the data
</li>
</ul>

<p>
<img src="figure/t-SNE/example-tSNE-grid-arxiv1001_1000.jpg" alt="example-tSNE-grid-arxiv1001_1000.jpg" />
t-SNE map of 1000 images from arXiv, organised by features extracted from VGG classifier
</p>

<p>
<img src="figure/t-SNE/tSNE_cuda_cs.CV_2012_n2000_p50_2019-06-18_16-35-11.png" alt="tSNE_cuda_cs.CV_2012_n2000_p50_2019-06-18_16-35-11.png" />
t-SNE map of images with the primary category of cs.CV (computer science, computer vision) from 2012 from arXiv, organised by features extracted from VGG classifier
</p>

<ul class="org-ul">
<li>Generating images using the image dataset using generative adversarial networks
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> Code</h3>
<div class="outline-text-3" id="text-1-3">
<p>
This repository contains code, statistics, and images produced throughout the project. These materials are mostly concerned with looking at the dataset of all the images, text, and metadata contained within the [arXiv](arXiv.org) source files.
</p>

<p>
For detailed instructions on running the code, please look in the [methods](methods/) folder.
</p>

<p>
Code is written using bash, python, SQLite, jupyter, and anaconda. Tested on Ubuntu 18.04 with NVidia graphics card.
</p>
</div>
</div>
<div id="outline-container-sec-1-4" class="outline-3">
<h3 id="sec-1-4"><span class="section-number-3">1.4</span> Project Methodology</h3>
</div>

<div id="outline-container-sec-1-5" class="outline-3">
<h3 id="sec-1-5"><span class="section-number-3">1.5</span> People</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li>Professor Anna Munster, UNSW Art &amp; Design
</li>
<li>Professor Adrian Mackenzie, Australian National University
</li>
<li>Kynan Tan, Postdoctoral Fellow, UNSW Art &amp; Design
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-1-6" class="outline-3">
<h3 id="sec-1-6"><span class="section-number-3">1.6</span> Licence</h3>
</div>
<div id="outline-container-sec-1-7" class="outline-3">
<h3 id="sec-1-7"><span class="section-number-3">1.7</span> Credits</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Code uses examples from
</p>
<ul class="org-ul">
<li>Machine Learning for Artists <a href="https://ml4a.github.io">ML4A</a>
</li>
<li>Mario Klingemann's <a href="https://github.com/Quasimondo/RasterFairy">RasterFairy</a>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-1-8" class="outline-3">
<h3 id="sec-1-8"><span class="section-number-3">1.8</span> Acknowledgements</h3>
<div class="outline-text-3" id="text-1-8">
<p>
Project supported by an Australian Research Council Discovery Grant
</p>
</div>
</div>
</div>
</div>
</body>
