{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ternary Classifier Predictions\n",
    "\n",
    "Uses a previously trained network to classify images and then saves the resulting prediction averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import clear_output, display\n",
    "import PIL.Image\n",
    "\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D, Dropout, Flatten, Conv2D, Activation\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array # load_img\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this seems to help with some GPU memory issues\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('ternary_20190911_9748x/diagram-sensor-unsure_vgg16-2000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sqlite3 database and create a cursor\n",
    "db_path = \"/home/rte/data/db/arxiv_db_images.sqlite3\"\n",
    "db = sqlite3.connect(db_path)\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list primary categories by alphabetical order\n",
    "\n",
    "# c.execute('''\n",
    "#     SELECT substr(trim(metadata.cat),1,instr(trim(metadata.cat)||' ',' ')-1), count(metadata.identifier)\n",
    "#     FROM metadata\n",
    "#     GROUP BY substr(trim(metadata.cat),1,instr(trim(metadata.cat)||' ',' ')-1)\n",
    "#     ORDER BY substr(trim(metadata.cat),1,instr(trim(metadata.cat)||' ',' ')-1) ASC    \n",
    "#     ''')\n",
    "# rows = c.fetchall()\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "# print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the list of categories in catlist\n",
    "\n",
    "# catlist = rows\n",
    "# for cat in catlist:\n",
    "#     print(str(cat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in catlist:\n",
    "#     pred.append([str(cat[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either get the data from SQLite DB, or use the pre-pickled version ^_^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of images for each year by category\n",
    "\n",
    "# sql = ('''\n",
    "#     SELECT count(images.identifier), strftime(\"%Y\", metadata.created) as 'Y'\n",
    "#     FROM images\n",
    "#     LEFT JOIN metadata on images.identifier = metadata.identifier\n",
    "#     WHERE substr(trim(cat),1,instr(trim(cat)||' ',' ')-1) = ?\n",
    "#     GROUP BY strftime(\"%Y\", metadata.created)\n",
    "#     ORDER BY strftime(\"%Y\", metadata.created) ASC\n",
    "#     ''')\n",
    "\n",
    "# data = []\n",
    "\n",
    "# for cat in catlist:\n",
    "#     print(\"querying for category: \" + str(cat[0]))\n",
    "#     c.execute(sql, (cat[0], ))\n",
    "#     rows = c.fetchall()\n",
    "    \n",
    "# #     print(\"total number of images found: \" + str(len(rows)))\n",
    "#     print(rows)\n",
    "# #     print(\"total number of articles: \" + rows[0][0])\n",
    "\n",
    "#     years = []\n",
    "#     totals = []\n",
    "    \n",
    "#     for row in rows:\n",
    "#         years.append(row[1])\n",
    "#         totals.append(row[0])\n",
    "        \n",
    "#     newdata = [cat[0], years, totals]\n",
    "#     data.append(newdata)\n",
    "\n",
    "# print(\"*\" * 20)\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pkl_filename = \"../sqlite-scripts/images_cat_year_data.pkl\"\n",
    "\n",
    "# READ PKL\n",
    "with open(image_pkl_filename, \"rb\") as read_file:\n",
    "    image_data = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = image.load_img(path, target_size=model.input_shape[1:3])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run prediction\n",
    "\n",
    "Code below queryies the SQLite DB for a particular category and year and returns all of the image IDs. These are then used to check if the converted jpg file exists. \n",
    "\n",
    "Those files are passed to the model which gives a prediction. The top class prediction totals are saved in the big ```image_data``` list.\n",
    "\n",
    "Later the percentage probability for each class is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = ('''\n",
    "    SELECT images.id\n",
    "    FROM images\n",
    "    LEFT JOIN metadata on images.identifier = metadata.identifier\n",
    "    WHERE substr(trim(cat),1,instr(trim(cat)||' ',' ')-1) = ?\n",
    "    AND strftime(\"%Y\", metadata.created) = ?\n",
    "    ''')\n",
    "\n",
    "imagefolder = \"/mnt/hd2/images/all/\"\n",
    "classes = [\"diagram\", \"sensor\", \"unsure\"]\n",
    "\n",
    "for index, cat in enumerate(image_data[:2]):\n",
    "    print(cat[0]) # category string\n",
    "    cat_class_totals = []\n",
    "    for year in cat[1]:\n",
    "        print(year) # year\n",
    "\n",
    "        c.execute(sql, (cat[0], year))\n",
    "        rows = c.fetchall()            \n",
    "        \n",
    "        class_totals = [0, 0, 0]\n",
    "                \n",
    "#         print(\"image files:\",rows)\n",
    "        random.seed(4)\n",
    "        random.shuffle(rows)\n",
    "#         print(\"shuffled:\", rows)\n",
    "    \n",
    "        # get a maximum of 1000 rows from the randomly sorted results\n",
    "\n",
    "        for i, row in enumerate(rows[:1000]):\n",
    "            print(i, row)\n",
    "            imagefilepath = os.path.join(imagefolder, str(row[0]) + \".jpg\")\n",
    "            print(imagefilepath)\n",
    "            try:\n",
    "                img, x = load_image(imagefilepath)\n",
    "                img.verify() # verify that it is, in fact an image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print('Bad file:', imagefilepath) # print out the names of corrupt files\n",
    "            predictions = model.predict(x)\n",
    "            print(predictions[0])\n",
    "\n",
    "            ind = np.argmax(predictions)\n",
    "            class_totals[ind] +=1\n",
    "            pred = classes[ind]\n",
    "            print(ind, pred)\n",
    "\n",
    "            print(\"*\" * 20)\n",
    "\n",
    "        print(class_totals)\n",
    "        cat_class_totals.append(class_totals)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(cat_class_totals)\n",
    "    image_data[index].append(cat_class_totals)\n",
    "    \n",
    "    # WRITE\n",
    "    with open(\"ternary_classifier_predictions.pkl\", \"wb\") as write_file:\n",
    "        pickle.dump(image_data, write_file)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"*** DONE ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
