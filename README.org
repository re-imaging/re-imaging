
* Re-imaging the empirical: statistical visualisation in art and science
** Project Description

/Re-imaging the empirical/ is a research project investigating the visual cultures of machine learning (ML). It is interested in the dominant role that images play in many contemporary ML projects and endeavours from AlphaGo through to style transfer. It also asks how images are used by ML models and techniques as part of a broader re-contouring of what it is to both see and know the empirical world. We use ML methods in this project to look at big datasets drawn from ML scientific scholarship to detect vectors and differences in images and their interrelations; images that have themselves been generated by ML research in statistics, physics, mathematics, computer vision and more.

The project has three threads:

- Tracing the genealogies and interrelations of images generated as a result of ML research
- Developing a new theoretical framework for thinking changes in seeing, images, and perception in a culture(s) of ML
- Investigating the role of artistic visual experimentation with ML as a space that reflexively foregrounds new ways of seeing and perceiving shaped by ML computation.

** Project Outline

- Downloading and extracting the arXiv source dataset - see [[arxiv-src-scripts/arxiv_extract.sh][arxiv_extract.sh]]
- Creating an SQLite database to index each image and link to metadata - [[sqlite-scripts][sqlite-scripts]]
- Querying dataset for various statistics regarding image formats, dimensions, category distributions etc. - see [[statistics][statistics]], e.g. [[statistics/data-statistics.org][general data statistics]]
- Running machine learning techniques such as image classification and dimensionality reduction across data
- Producing t-SNE maps of the distribution of different image features within subsets of the data

#+name:t-SNE1
#+caption: t-SNE map of 1000 images from arXiv, organised by features extracted from VGG classifier
[[file:figures/t-SNE/example-tSNE-grid-arxiv1001_1000.jpg]]
t-SNE map of 1000 images from arXiv, organised by features extracted from VGG classifier

#+name:t-SNE1
#+caption: t-SNE map of images with the primary category of cs.CV (computer science, computer vision) from 2012 from arXiv, organised by features extracted from VGG classifier
[[file:figures/t-SNE/tSNE_cuda_cs.CV_2012_n2000_p50_2019-06-18_16-35-11.png]]
t-SNE map of images with the primary category of cs.CV (computer science, computer vision) from 2012 from arXiv, organised by features extracted from VGG classifier

- Generating images using the image dataset using generative adversarial networks

** Code
This repository contains code, statistics, and images produced throughout the project. These materials are mostly concerned with looking at the dataset of all the images, text, and metadata contained within the [arXiv](arXiv.org) source files.

For detailed instructions on running the code, please look in the [[methods/][methods]] folder.

Code is written using bash, python, SQLite, jupyter, and anaconda. Tested on Ubuntu 18.04 with NVidia graphics card.
** Project Methodology

** People
- Professor Anna Munster, UNSW Art & Design
- Professor Adrian Mackenzie, Australian National University
- Kynan Tan, Postdoctoral Fellow, UNSW Art & Design
** Licence
** Credits
Code uses examples from
- Machine Learning for Artists [[https://ml4a.github.io][ML4A]]
- Mario Klingemann's [[https://github.com/Quasimondo/RasterFairy][RasterFairy]]
** Acknowledgements
Project supported by an Australian Research Council Discovery Grant
