{% extends 'base.html' %}

{% block header %}
  <h1>{% block title %}About{% endblock %}</h1>
{% endblock %}

{% block content %}

<div>
  <nav id="nav-menu" class="nav col-2 mr-1 pr-1 mt-1 d-flex justify-content-end" style="z-index: 999;">
    <div class="d-flex flex-column">
      <!-- <a class="navbar-brand" href="#">Reconfiguring</a> -->
      <li class="nav-item d-flex justify-content-end">
        <a class="nav-link" href="{{ url_for('core.about') }}">About</a>
      </li>
      <li class="nav-item d-flex justify-content-end">
        <a class="nav-link active" href="{{ url_for('core.get_images') }}">Interface</a>
      </li>
    </div>
  </nav>
</div>

<div class="about">
{% filter markdown %}

## arXiv Images

This web application is an interactive visualisation of the images found in the arXiv repository. This is currently in alpha and will be made more widely available in the near future.

This version uses 600,000 images from a total of over 12 million in the arXiv bulk dataset up to July 2020.

[ArXiv](https://arxiv.org/) is a repository that maintains over 1.5 million e­print articles across a diverse range of scientific fields. It provides access to metadata and bulk source data downloads. While this data has been widely examined, it has not been used, to our knowledge, to investigate the images that contribute to this research.

This project draws inspiration from [imgs.ai](https://imgs.ai/), developed by Fabian Offert, with contributions by Peter Bell and Oleg Harlamov.

## Screencast

(screencast to go here, showing how to use the interface and some example searches)

## Running searches

The dataset can be searched either by randomly sampling the dataset or by pulling the nearest neighbours to a target image according to a particular machine learning embedding. Toggle the switch to choose the search mode. If using the ML embedding, you are required to select an image by clicking on one from the grid. Searching will then bring up the nearest neighbours to that image according to that embedding. Selected image has no effect on the random sampling.

On top of this, the results can be filtered according to the metadata of the image, paper, and associated caption. Click on the optional filters button to see available filters. Many of these can be searched for the top results, while some fields require typing a keyword, such as title, caption, or abstract.

## Embeddings

There are four embeddings currently available. Each embedding is the created by using a particular neural network to process each image in the dataset and then saving the resulting data. This data was further reduced using Principle Component Analysis, for this we used the [Scikit Learn IncrementalPCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html). The reduced data was then used to construct a nearest neighbours map using the [Annoy library](https://github.com/spotify/annoy), which allows for fast approximate k-nearest neighbours over large sets of data.

### ternary

This classifier was trained using manually labelled images. The researchers labelled 9748 randomly sampled images from arXiv as either diagram, sensor, or mixed. Sensor refers to images that appear to have been captured using photography or other capture devices. This classifer was then trained on these images and achieved accuracy of 92.07% on the cross-validation dataset. While the classifier has learned features of the images, due to the small number of training samples there are a number of strange results produced when run over the larger subset of data.

### VGG16

The VGG16 architecture, pre-trained on ImageNet. We used the [Keras](https://keras.io/) implementation. This classifier achieves high accuracy on ImageNet. Note also that the top-5 predictions using VGG16 have been saved in the metadata.

### raw

The raw pixels of each image. Generally produces associations based on overall colour content.

### cats

A classifier trained on images of cats vs dogs. We used keras to train this network, following [this example](https://keras.io/examples/vision/image_classification_from_scratch/). Produces some unlikely associations between images.

## Acknowledgements

The full title of this project is: ‘Re­imaging the Empirical: statistical visualisation in art and science’ (2017–2021). Professor Anna Munster (University of New South Wales) is lead investigator and collaborating with Professor Adrian Mackenzie (Australian Na­tional University) and Dr Kynan Tan, Postdoctoral Fellow (University of New South Wales). This is a Discovery Project funded by the Australian Research Council.

{% endfilter %}
<!-- </div>

<div>
  <nav class="nav-menu">
    <ul>
      <li><a href="{{ url_for('core.about') }}">About</a>
      <li><a href="{{ url_for('core.get_images') }}">Interface</a>
    </ul>
  </nav>
</div> -->

{% endblock %}
