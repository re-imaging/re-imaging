{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "import itertools\n",
    "import subprocess\n",
    "import os\n",
    "import shlex\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA, IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# for tf 2\n",
    "# from keras.applications.imagenet_utils import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this seems to help with some GPU memory issues\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"vgg\"\n",
    "mode = \"raw\"\n",
    "# mode = \"dc\"\n",
    "# mode = \"ternary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size = 2000 # testing\n",
    "# dataset_size = 120000\n",
    "# dataset_size = 600000 # for saving IPCA files from 5% of data\n",
    "dataset_size = 1200000 # for testing larger ann files\n",
    "batch_size = 2000\n",
    "num_images = dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_filename = \"test_5k_pca.ann\"\n",
    "# ann_filename = \"120k_ipca.ann\"\n",
    "# ann_filename = \"120k_vgg_ipca.ann\"\n",
    "\n",
    "# ann_filename = \"2k_pca.ann\"\n",
    "# ann_filename = \"2k_ipca.ann\"\n",
    "# ann_filename = \"2k_raw.ann\"\n",
    "# ann_filename = \"2k_vgg_ipca.ann\"\n",
    "# ann_filename = \"2k_ternary.ann\"\n",
    "\n",
    "# ann_filename = \"600k_vgg_ipca.ann\"\n",
    "# ann_filename = \"600k_raw.ann\"\n",
    "# ann_filename = \"600k_ternary.ann\"\n",
    "\n",
    "# ann_filename = f'{dataset_size / 1000000:02.1f}m_{mode}.ann'\n",
    "ann_filename = f'{dataset_size / 1000:01.0f}k_{mode}.ann'\n",
    "print(ann_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load image filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_list = \"/home/rte/data/paths/all_converted_jpg_images_shuf.txt\"\n",
    "# image_list = \"/home/rte/data/paths/all_images_ordered.txt\"\n",
    "image_list = \"/home/rte/data/paths/all_images_shuf.txt\"\n",
    "\n",
    "# image_folder = \"/home/rte/data/images/web/120k/\"\n",
    "image_folder = \"/mnt/hd2/images/all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "\n",
    "with open(image_list, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(\"length:\",len(lines))\n",
    "    print(lines[0])\n",
    "for l in lines:\n",
    "    # substrings = l.rsplit(\",\", 1)\n",
    "    filepaths.append(l.strip())\n",
    "    # image_ids.append(substrings[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the image paths for all images that we have features for\n",
    "images = []\n",
    "\n",
    "for i, f in enumerate(filepaths[:]):\n",
    "    images.append(image_folder + f)\n",
    "print(len(images))\n",
    "print(images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize to make sure we don't try and read more images than we have\n",
    "filepaths = filepaths[:dataset_size]\n",
    "print(len(filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # images as arrays\n",
    "dim = 256 # size of one dimension\n",
    "f = dim * dim # size of vector\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, dim):\n",
    "    im = Image.open(path).convert('RGB')\n",
    "    img_x, img_y = im.size\n",
    "\n",
    "    # im.show()\n",
    "\n",
    "    if False:\n",
    "        x_bigger = True if img_x > img_y else False\n",
    "        ratio = img_x / img_y\n",
    "\n",
    "        if x_bigger:\n",
    "            factor = float(dim) / img_y \n",
    "        else:\n",
    "            factor = float(dim) / img_x\n",
    "        new_x = int(img_x * factor)\n",
    "        new_y = int(img_y * factor)\n",
    "\n",
    "        resized = im.resize((new_x, new_y), Image.ANTIALIAS)\n",
    "        # resized.show()\n",
    "\n",
    "        left = (new_x - dim)/2\n",
    "        top = (new_y - dim)/2\n",
    "        right = (new_x + dim)/2\n",
    "        bottom = (new_y + dim)/2\n",
    "\n",
    "        cropped = resized.crop((left, top, right, bottom))\n",
    "#         cropped.show()\n",
    "\n",
    "#     print(\"factor\", factor)\n",
    "#     print(\"ratio\", ratio)\n",
    "#     print(x_bigger)\n",
    "#     print(\"img_x\", img_x)\n",
    "#     print(\"img_y\", img_y)\n",
    "#     print(new_x, new_y)\n",
    "#     print(\"cropped\", cropped.size)\n",
    "\n",
    "    if True:\n",
    "        # just resize to fill the box\n",
    "        just_resize = im.resize((dim, dim), Image.ANTIALIAS)\n",
    "    #     just_resize.show()\n",
    "        return just_resize\n",
    "\n",
    "    if False:\n",
    "        if x_bigger:\n",
    "            factor = float(dim) / img_x\n",
    "        else:\n",
    "            factor = float(dim) / img_y\n",
    "        new_x = int(img_x * factor)\n",
    "        new_y = int(img_y * factor)\n",
    "    #     print(\"factor\", factor)\n",
    "    #     print(\"img_x\", img_x)\n",
    "    #     print(\"img_y\", img_y)\n",
    "        crop_resized = im.resize((new_x, new_y), Image.ANTIALIAS)\n",
    "\n",
    "        # pad\n",
    "        padded = Image.new(\"RGB\", (dim, dim))\n",
    "        padded.paste(crop_resized, ((dim - new_x)//2, (dim - new_y)//2))\n",
    "        padded.show()\n",
    "    \n",
    "#     return just_resize\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_worker(filename):\n",
    "    img_data = np.array(load_img(filename, dim))# - mean\n",
    "    return img_data\n",
    "\n",
    "def image_worker_flat(filename):\n",
    "    img_data = np.array(load_img(filename, dim)).flatten()# - mean\n",
    "    return img_data\n",
    "\n",
    "def image_worker_vgg(filename):\n",
    "    img, x = load_image(filename);\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([224.03429894, 223.6761458, 223.62304944]) # mean for 120k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img(images[8], dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images\n",
    "\n",
    "Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    image_batch = images[:num_images]\n",
    "    overall_start = time.time()\n",
    "    with Pool(num_workers) as p:\n",
    "        X = p.map(image_worker_flat, image_batch)\n",
    "    print(f\"loaded {len(X)} images | time taken: {time.time() - overall_start}\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"ternary\":\n",
    "    model_path = \"/home/rte/re-imaging/classification/checkpoints/ternary_20190911_9748x/diagram-sensor-unsure_vgg16-2000.hdf5\"\n",
    "    model = keras.models.load_model(model_path)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"vgg\":\n",
    "    model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode in (\"vgg\", \"ternary\"):\n",
    "    def load_image(path):\n",
    "        img = image.load_img(path, target_size=model.input_shape[1:3])\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode in (\"vgg\", \"ternary\"):\n",
    "    img, x = load_image(images[8])\n",
    "    print(\"shape of x: \", x.shape)\n",
    "    print(\"data type: \", x.dtype)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"vgg\":\n",
    "    predictions = model.predict(x)\n",
    "\n",
    "    for _, pred, prob in decode_predictions(predictions)[0]:\n",
    "        print(\"predicted %s with probability %0.3f\" % (pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"vgg\":\n",
    "    feat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"fc2\").output)\n",
    "    feat_extractor.summary()\n",
    "if mode == \"ternary\":\n",
    "    feat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"dense_1\").output)\n",
    "    feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=n_components, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feed ipca in batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_batch_size = batch_size\n",
    "# batch_size = 500\n",
    "assert dataset_size % batch_size == 0, \"dataset_size not a multiple of batch_size\"\n",
    "divisions = [x for x in range(0, dataset_size, batch_size)]\n",
    "print(\"divisions:\",divisions)\n",
    "overall_start = time.time()\n",
    "\n",
    "for div in divisions:\n",
    "    X = []\n",
    "#     print(\"batch:\",div,div+batch_size)\n",
    "#     for i, image in enumerate(images[div:div+batch_size]):\n",
    "#         img_data = np.array(load_img(images[i], dim)) - mean\n",
    "#         X.append(img_data.flatten())\n",
    "    \n",
    "    if mode in (\"vgg\", \"ternary\"):\n",
    "        print(\"loading images for VGG or ternary classifier\")\n",
    "        start = time.time()\n",
    "        with Pool(num_workers) as p:\n",
    "            X = p.map(image_worker_vgg, images[div:div+batch_size])\n",
    "        print(f\"batch{div,div+batch_size} - time to load images: {time.time() - start}\")    \n",
    "\n",
    "        # extract features\n",
    "        features = []\n",
    "        for x in X:\n",
    "            feat = feat_extractor.predict(x)[0]\n",
    "            features.append(feat)\n",
    "        print(f\"extracted features of {len(X)} images, time taken: {time.time() - start}\")\n",
    "        X = features\n",
    "    else:\n",
    "        print(\"loading images for raw processing\")\n",
    "        start = time.time()\n",
    "        with Pool(num_workers) as p:\n",
    "            X = p.map(image_worker_flat, images[div:div+batch_size])\n",
    "        print(f\"batch{div,div+batch_size} - time to load images: {time.time() - start}\")    \n",
    "        \n",
    "    print(X[0])\n",
    "    print(\"size of data\", len(X))\n",
    "    start = time.time()\n",
    "    ipca.partial_fit(X)\n",
    "    print(f\"partial fit time taken: {time.time() - start}\")\n",
    "print(f\"total time taken: {time.time() - overall_start}\")\n",
    "# batch_size = old_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ipca = ipca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib_path = \"ipca_2k_test.joblib\"\n",
    "# joblib_path = \"ipca_120k_test.joblib\"\n",
    "joblib_path = ann_filename.split(\".\")[0] + \"_ipca.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joblib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write joblib file to save ipca\n",
    "with open(joblib_path, \"wb\") as f:\n",
    "    joblib.dump(ipca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_samples_seen_:\", ipca.n_samples_seen_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ipca\n",
    "Testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(joblib_path, \"rb\") as f:\n",
    "#     load_ipca = joblib.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(load_ipca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(load_ipca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(load_ipca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.cumsum(load_ipca.explained_variance_ratio_))\n",
    "# plt.title(joblib_path)\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance');\n",
    "# plot_savename = joblib_path.split(\".\")[0] + \"_expvarrat.png\"\n",
    "# plt.savefig(plot_savename, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca\n",
    "t = AnnoyIndex(300, 'angular')  # Length of item vector that will be indexed\n",
    "\n",
    "# raw\n",
    "# t = AnnoyIndex(256*256*3, 'angular')  # Length of item vector that will be indexed\n",
    "\n",
    "t.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed annoy all in one go\n",
    "\n",
    "# annoy_data = X_pca\n",
    "# annoy_data = X_ipca\n",
    "# # annoy_data = X\n",
    "# print(\"length of annoy_data:\", len(annoy_data))\n",
    "\n",
    "# for i, item in enumerate(annoy_data):\n",
    "#     t.add_item(i, item)\n",
    "\n",
    "# start = time.time()\n",
    "# t.build(10) # 10 trees\n",
    "# t.save(ann_filename)\n",
    "# print(f\"added all to annoy, time taken: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed annoy in batches\n",
    "assert dataset_size % batch_size == 0, \"dataset_size not a multiple of batch_size\"\n",
    "divisions = [x for x in range(0, dataset_size, batch_size)]\n",
    "print(\"divisions:\",divisions)\n",
    "overall_start = time.time()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for div in divisions:\n",
    "    X = []\n",
    "#     print(\"batch:\",div,div+batch_size)\n",
    "#     for i, image in enumerate(images[div:div+batch_size]):\n",
    "#         img_data = np.array(load_img(images[i], dim)) - mean\n",
    "#         X.append(img_data.flatten())\n",
    "\n",
    "    if mode in (\"vgg\", \"ternary\"):\n",
    "        print(\"loading images for VGG\")\n",
    "        start = time.time()\n",
    "        with Pool(num_workers) as p:\n",
    "            X = p.map(image_worker_vgg, images[div:div+batch_size])\n",
    "        print(f\"batch{div,div+batch_size} - time to load images: {time.time() - start}\")    \n",
    "\n",
    "        # extract features\n",
    "        features = []\n",
    "        for x in X:\n",
    "            feat = feat_extractor.predict(x)[0]\n",
    "            features.append(feat)\n",
    "        print(f\"extracted features of {len(X)} images, time taken: {time.time() - start}\")\n",
    "        X = features\n",
    "    else:\n",
    "        print(\"loading images for raw\")\n",
    "        start = time.time()\n",
    "        with Pool(num_workers) as p:\n",
    "            X = p.map(image_worker_flat, images[div:div+batch_size])\n",
    "        print(f\"batch{div,div+batch_size} - loading time taken: {time.time() - start}\")\n",
    "    start = time.time()\n",
    "    ipca_X = ipca.transform(X)\n",
    "    print(f\"transform time taken: {time.time() - start}\")\n",
    "    start = time.time()\n",
    "    for i, item in enumerate(ipca_X):\n",
    "        t.add_item(counter, item)\n",
    "        counter += 1\n",
    "    print(f\"annoy add items time taken: {time.time() - start}\")\n",
    "print(f\"total time taken: {time.time() - overall_start}\")\n",
    "\n",
    "t.build(10) # 10 trees\n",
    "t.save(ann_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images to check ANN\n",
    "\n",
    "run in loop for first 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_n = 50\n",
    "\n",
    "for i in range(10):\n",
    "    target_index = i\n",
    "    print(\"index\", target_index)\n",
    "    indexes = t.get_nns_by_item(target_index, num_n)\n",
    "    print(indexes)\n",
    "    target_images = np.array(images)[np.array(indexes)]\n",
    "    \n",
    "    xdim = 8\n",
    "    ydim = 7\n",
    "\n",
    "    fig, ax = plt.subplots(ydim, xdim)\n",
    "    fig.set_size_inches(10, 12)\n",
    "#     fig.patch.set_facecolor('0.98')\n",
    "    #     print(filepaths[index].split(\".\")[0])\n",
    "    title_string = f'annoy test: {mode}'\n",
    "#     print(title_string)\n",
    "    fig.suptitle(title_string, y=0.9)\n",
    "\n",
    "    # display the query image\n",
    "    query_image = mpimg.imread(images[target_index])\n",
    "    ax[0, 0].imshow(query_image, cmap='Greys_r')\n",
    "    ax[0, 0].set_title(\"query ID: \" + filepaths[target_index].split(\".\")[0], pad=20)\n",
    "\n",
    "    for i in range(xdim):\n",
    "        ax[0, i]. axis('off')\n",
    "\n",
    "    for y in range(1, ydim):\n",
    "        for x in range(xdim):\n",
    "#             print(f\"x: {x}, y: {y}\")\n",
    "            grid_index = (y * xdim) + x - xdim\n",
    "#             print(f\"grid_index: {grid_index}\")\n",
    "            current_image = mpimg.imread(target_images[grid_index])\n",
    "            ax[y, x].imshow(current_image, cmap='Greys_r')\n",
    "            ax[y, x].axis('off')\n",
    "\n",
    "#     plt.tight_layout(pad=0.5)\n",
    "    savename = f\"{ann_filename.split('.')[0]}_{target_index}.jpg\"\n",
    "    # savename = f'{query_image_idx:04}' + \"_\" + filepaths[index].split(\".\")[0] + \"_strip_1m.jpg\"\n",
    "    plt.savefig(savename, dpi=300, bbox_inches='tight')\n",
    "    # print(\"completed\", index)\n",
    "    # print(\"time taken\", \"{:.4f}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
