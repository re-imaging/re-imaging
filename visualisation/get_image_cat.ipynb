{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "import itertools\n",
    "import subprocess\n",
    "import os\n",
    "import shlex\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path on rte\n",
    "db_path = \"/home/rte/data/db/arxiv_db_images.sqlite3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import the sqlite3 database and create a cursor\n",
    "\n",
    "db = sqlite3.connect(db_path)\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sqlite database connection\n",
    "\n",
    "c.execute('PRAGMA TABLE_INFO({})'.format(\"metadata\"))\n",
    "info = c.fetchall()\n",
    "\n",
    "print(\"\\nColumn Info:\\nID, Name, Type, NotNull, DefaultVal, PrimaryKey\")\n",
    "for col in info:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read predictions text file with format\n",
    "# filename,p1,%,p2,%,...p5,%\n",
    "\n",
    "filename = \"predictions_100k.txt\"\n",
    "predictions = []\n",
    "\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        substrings = line.split(\",\")\n",
    "        predictions.append(substrings)\n",
    "print(len(predictions))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids from the bigger list\n",
    "\n",
    "ids = []\n",
    "\n",
    "for row in predictions:\n",
    "    ids.append(row[0].split(\".\")[0])\n",
    "print(len(ids))\n",
    "print(ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find full categories for each entry in our list and put into another list\n",
    "\n",
    "found_cats = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sql = ('''\n",
    "    SELECT images.id, metadata.cat\n",
    "    FROM images\n",
    "    LEFT JOIN metadata on images.identifier = metadata.identifier\n",
    "    WHERE images.id in ?\n",
    "    ''')\n",
    "\n",
    "# attempt to read all in one SQLite query.\n",
    "# sort of works but results are reordered according to the database order\n",
    "\n",
    "# c.execute('SELECT images.id, metadata.cat FROM images LEFT JOIN metadata on images.identifier = metadata.identifier WHERE images.id in ({0})'.format(', '.join('?' for _ in ids)), ids)\n",
    "\n",
    "# rows = c.fetchall()\n",
    "# print(len(rows))\n",
    "\n",
    "'''\n",
    "for i, identifier in enumerate(predictions[:]):\n",
    "    if i % 100 == 0:\n",
    "        print(\"search total:\",i)\n",
    "        print(\"time taken:\",time.time()-start)\n",
    "    idx = identifier[0].split(\".\")[0]\n",
    "#     print(\"querying for id: \" + str(idx))\n",
    "    c.execute(sql, (idx, ))\n",
    "    result = c.fetchall()\n",
    "#     print(\"results:\",result)\n",
    "#     print(\"cat:\",result[0][1])\n",
    "    found_cats.append(result[0][1])\n",
    "'''\n",
    "\n",
    "print(found_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rows[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
