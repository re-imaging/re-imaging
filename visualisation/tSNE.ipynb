{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing tsnecuda -- not currently working\n",
    "\n",
    "from tsnecuda import TSNE\n",
    "# from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((5000, 50))\n",
    "X_embedded = TSNE(verbose=1).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# from pillow import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check PIL and Pillow version numbers\n",
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)\n",
    "print('PIL Version:', PIL.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-trained model\n",
    "# model = keras.applications.densenet.DenseNet201(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = image.load_img(path, target_size=model.input_shape[1:3])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!identify \"/home/rte/data/images/1001/converted_256/00000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, x = load_image(\"/home/rte/data/images/1001/converted_256/00000001.jpg\")\n",
    "print(\"shape of x: \", x.shape)\n",
    "print(\"data type: \", x.dtype)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)\n",
    "\n",
    "for _, pred, prob in decode_predictions(predictions)[0]:\n",
    "    print(\"predicted %s with probability %0.3f\" % (pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"fc2\").output)\n",
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, x = load_image(\"/home/rte/data/images/1001/converted_256/00000001.jpg\")\n",
    "print(\"shape of x: \", x.shape)\n",
    "print(\"data type: \", x.dtype)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image path here!\n",
    "# images_path = '/home/rte/data/images/cat/cs.CV/2015/'\n",
    "images_path = '/home/rte/data/images/random/seq/0-100k/tsne/'\n",
    "\n",
    "category = images_path.split('/')[6]\n",
    "year = images_path.split('/')[7]\n",
    "\n",
    "image_extensions = ['.jpg', '.png', '.jpeg']   # case-insensitive (upper/lower doesn't matter)\n",
    "max_num_images = 100000\n",
    "\n",
    "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(images_path) for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "if max_num_images < len(images):\n",
    "    images = [images[i] for i in sorted(random.sample(range(len(images)), max_num_images))]\n",
    "\n",
    "print(\"keeping %d images to analyze\" % len(images))\n",
    "\n",
    "num_x = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = len(images)\n",
    "print(num_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category)\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "\n",
    "features = []\n",
    "for i, image_path in enumerate(images):\n",
    "    if i % 500 == 0:\n",
    "        toc = time.clock()\n",
    "        elap = toc-tic;\n",
    "        print(\"analyzing image %d / %d. Time: %4.4f seconds.\" % (i, len(images),elap))\n",
    "        tic = time.clock()\n",
    "    img, x = load_image(image_path);\n",
    "    feat = feat_extractor.predict(x)[0]\n",
    "    features.append(feat)\n",
    "\n",
    "print('finished extracting features for %d images' % len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# have a look at a few plots for comparison\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "features = np.array(features)\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = pca.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# grab a random query image\n",
    "query_image_idx = int(len(images) * random.random())\n",
    "\n",
    "# let's display the image\n",
    "img = image.load_img(images[query_image_idx])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "similar_idx = [ distance.cosine(pca_features[query_image_idx], feat) for feat in pca_features ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_closest = sorted(range(len(similar_idx)), key=lambda k: similar_idx[k])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the similarity results as thumbnails of height 100\n",
    "thumbs = []\n",
    "for idx in idx_closest:\n",
    "    img = image.load_img(images[idx])\n",
    "    img = img.resize((int(img.width * 100 / img.height), 100))\n",
    "    thumbs.append(img)\n",
    "\n",
    "# concatenate the images into a single image\n",
    "concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n",
    "\n",
    "# show the image\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(concat_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_images(query_image_idx, num_results=5):\n",
    "    distances = [ distance.cosine(pca_features[query_image_idx], feat) for feat in pca_features ]\n",
    "    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:num_results+1]\n",
    "    return idx_closest\n",
    "\n",
    "def get_concatenated_images(indexes, thumb_height):\n",
    "    thumbs = []\n",
    "    for idx in indexes:\n",
    "        img = image.load_img(images[idx])\n",
    "        img = img.resize((int(img.width * thumb_height / img.height), thumb_height))\n",
    "        thumbs.append(img)\n",
    "    concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n",
    "    return concat_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a query on a random image\n",
    "query_image_idx = int(len(images) * random.random())\n",
    "idx_closest = get_closest_images(query_image_idx)\n",
    "query_image = get_concatenated_images([query_image_idx], 300)\n",
    "results_image = get_concatenated_images(idx_closest, 200)\n",
    "\n",
    "# display the query image\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(query_image)\n",
    "plt.title(\"query image (%d)\" % query_image_idx)\n",
    "\n",
    "something, x = load_image(images[query_image_idx])\n",
    "predictions = model.predict(x)\n",
    "\n",
    "for _, pred, prob in decode_predictions(predictions)[0]:\n",
    "    print(\"predicted %s with probability %0.3f\" % (pred, prob))\n",
    "\n",
    "feat = feat_extractor.predict(x)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(feat[0])\n",
    "\n",
    "# display the resulting images\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(results_image)\n",
    "plt.title(\"similar images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we still have the features and list of images\n",
    "for img, f in list(zip(images, pca_features))[0:5]:\n",
    "    print(\"image: %s, features: %0.2f,%0.2f,%0.2f,%0.2f... \"%(img, f[0], f[1], f[2], f[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp = 50\n",
    "bPCA = True\n",
    "num_iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bPCA:\n",
    "    X = np.array(pca_features)\n",
    "else:\n",
    "    X = np.array(features)\n",
    "X.shape\n",
    "tsne = TSNE(n_components=2, learning_rate=150, perplexity=perp, angle=0.2, verbose=2, n_iter=num_iterations).fit_transform(X)\n",
    "\n",
    "# original command\n",
    "# tsne = TSNE(n_components=2, learning_rate=150, perplexity=30, angle=0.2, verbose=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise points\n",
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "full_image = Image.new('RGBA', (width, height))\n",
    "for img, x, y in zip(images, tx, ty):\n",
    "    tile = Image.open(img)\n",
    "    rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "    tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)\n",
    "    full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "imshow(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "filename = \"tSNE_\" + category + \"_\" + year + \"_\" + (\"feat\",\"pca\")[bPCA] + \"_n\" + str(num_iterations) + \"_p\" + str(perp) + \"_\" + st\n",
    "print(filename)\n",
    "full_image.save(filename + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/bmcfee/RasterFairy/ --user\n",
    "# import rasterfairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"tSNE_\" + category + \"_\" + year + \"_n\" + str(num_iterations) + \"_p\" + str(perp) + \"_\" + st\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "f = \"features_\" + category + \"_\" + year + \"_vgg_x\" + str(num_x) + \".pickle\"\n",
    "\n",
    "print(f)\n",
    "\n",
    "# WRITE\n",
    "with open(f, \"wb\") as write_file:\n",
    "    pickle.dump(features, write_file)\n",
    "    write_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ\n",
    "\n",
    "f = \"features_cs.CV_2012_vgg_x8381.pickle\"\n",
    "\n",
    "load_data = []\n",
    "\n",
    "with open(f, \"rb\") as read_file:\n",
    "    load_data = pickle.load(read_file)\n",
    "    read_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/rte/data/pickles/features_cat_pickle/features_cs.CV_2012_vgg_x8381.pickle' \n",
    "\n",
    "category = p.split('_')[3]\n",
    "year = p.split('_')[4]\n",
    "print(\"category: \" + category)\n",
    "print(\"year: \" + str(year))\n",
    "\n",
    "\n",
    "with open(p, \"rb\") as read_file:\n",
    "    images, features = pickle.load(read_file)\n",
    "    read_file.close()\n",
    "\n",
    "# check that we still have the features and list of images\n",
    "print(\"----- checking images and features -----\")\n",
    "print(\"length of images: \" + str(len(images)))\n",
    "print(\"length of features: \" + str(len(features)))\n",
    "for img, f in list(zip(images, features))[0:5]:\n",
    "    print(\"image: %s, features: %0.2f,%0.2f,%0.2f,%0.2f... \"%(img, f[0], f[1], f[2], f[3]))\n",
    "\n",
    "if len(images) >= 300:\n",
    "    features = np.array(features)\n",
    "    print(\"----- running pca across features -----\")\n",
    "    pca = PCA(n_components=300)\n",
    "    pca.fit(features)\n",
    "\n",
    "    pca_features = pca.transform(features)\n",
    "\n",
    "    X = np.array(pca_features)\n",
    "    X.shape\n",
    "    tsne = TSNE(n_components=2, learning_rate=150, perplexity=perp, angle=0.2, verbose=2, n_iter=num_iterations).fit_transform(X)\n",
    "\n",
    "    # normalise points\n",
    "    tx, ty = tsne[:,0], tsne[:,1]\n",
    "    tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "    ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))\n",
    "\n",
    "    width = 4000\n",
    "    height = 3000\n",
    "    max_dim = 100\n",
    "\n",
    "    full_image = Image.new('RGBA', (width, height))\n",
    "    for img, x, y in zip(images, tx, ty):\n",
    "        tile = Image.open(img)\n",
    "        rs = max(1, tile.width/max_dim, tile.height/max_dim)\n",
    "        tile = tile.resize((int(tile.width/rs), int(tile.height/rs)), Image.ANTIALIAS)\n",
    "        full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "\n",
    "    plt.figure(figsize = (16,12))\n",
    "    imshow(full_image)\n",
    "\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    filename = \"tSNE_\" + category + \"_\" + year + \"_n\" + str(num_iterations) + \"_p\" + str(perp) + \"_\" + st\n",
    "    print(filename)\n",
    "    full_image.save(filename + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = '/home/rte/data/pickles/tSNE_pickle_cuda/tSNE_cuda_cs.CV_2012_n2000_p50_2019-06-18_16-35-11.pickle'\n",
    "p = '/home/rte/data/pickles/tSNE_pickle_cuda/tSNE_cuda_stat.ML_2018_n2000_p50_2019-06-18_16-00-57.pickle' \n",
    "\n",
    "# filename = \"tSNE_cuda_\" + category + \"_\" + year + \"_n\" + str(num_iterations) + \"_p\" + str(perp) + \"_\" + st\n",
    "filename = \"tSNE_cuda_stat.ML_2018\"\n",
    "\n",
    "with open(p, \"rb\") as read_file:\n",
    "    images, tsne = pickle.load(read_file)\n",
    "    read_file.close()\n",
    "\n",
    "# normalise points\n",
    "tx, ty = tsne[:,0], tsne[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))\n",
    "\n",
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "print(\"----- creating image from tiles -----\")\n",
    "\n",
    "full_image = Image.new('RGBA', (width, height))\n",
    "for img, x, y in zip(images, tx, ty):\n",
    "    tile = Image.open(img)\n",
    "    tw = tile.width\n",
    "    th = tile.height\n",
    "    print(img)\n",
    "    print(\"tile dimensions: x=\" + str(tile.width) + \" y=\" + str(tile.height))\n",
    "    if tw < 10000 and th < 10000:\n",
    "        rs = max(1, tw/max_dim, th/max_dim)\n",
    "        tile = tile.resize((int(tw/rs), int(th/rs)), Image.ANTIALIAS)\n",
    "        full_image.paste(tile, (int((width-max_dim)*x), int((height-max_dim)*y)), mask=tile.convert('RGBA'))\n",
    "    else:\n",
    "        print(\"tile width or height too big?\")\n",
    "\n",
    "plt.figure(figsize = (16,12))\n",
    "imshow(full_image)\n",
    "\n",
    "print(\"saved file: \" + filename + \".png\")\n",
    "full_image.save(filename + \".png\")\n",
    "print(\"----- finished! file saved -----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
